<h1 align="center">
  <p> üìë Projeto de Arquitetura de Software - UFCG </p>
</h1>

## üìù Objetivo

### üìç Geral

Analisar o comportamento de um sistema que emprega uma arquitetura de microsservi√ßos em seu backend. O foco √© entender como o sistema reage quando um ou mais de seus microsservi√ßos recebem uma carga elevada. Especial aten√ß√£o √© dada √† maneira como o sistema gerencia essa sobrecarga, comparando cen√°rios com e sem a implementa√ß√£o de autoscaling.

### üìç Espec√≠fico

O objetivo √© realizar um teste de carga em um sistema com arquitetura de microsservi√ßos, observando seu comportamento e as m√©tricas resultantes. Em seguida, o mesmo teste ser√° aplicado ao sistema, mas desta vez em um cen√°rio que conta com um servi√ßo de autoscaling ativo. A compara√ß√£o desses dois cen√°rios proporcionar√° insights importantes sobre o desempenho do sistema sob diferentes condi√ß√µes.

## ‚öôÔ∏è Sistema

### üîñ Descri√ß√£o

O sistema √© um backend para e-commerce com API em Node.js, organizado em microsservi√ßos encapsulados em containers Docker. Segue os princ√≠pios da Clean Architecture, com um proxy server direcionando as solicita√ß√µes. Utiliza MongoDB para gest√£o de dados, com modelos definidos pelo Mongoose. A comunica√ß√£o entre certos microsservi√ßos √© feita atrav√©s do RabbitMQ e do protocolo AMQP.

O c√≥digo fonte deste sistema, que foi modificado para a realiza√ß√£o do experimento, est√° dispon√≠vel em um artigo detalhado no [Medium](https://medium.com/@nicholasgcc/building-scalable-e-commerce-backend-with-microservices-exploring-design-decisions-node-js-b5228080403b). Para uma compreens√£o mais profunda do projeto e das modifica√ß√µes realizadas, recomendamos a leitura deste artigo. O reposit√≥rio completo do c√≥digo fonte pode ser acessado [aqui](https://github.com/nicholas-gcc/nodejs-ecommerce-microservice).

### üì¶ Arquitetura
A arquitetura do sistema, com as modifica√ß√µes aplicadas, √© apresentada abaixo:

![Arquitetura no Docker](/.github/assets/images/docker_architecture.png)

## ü™Ñ Experimento

### üõ†Ô∏è Ferramentas utilizadas

O experimento envolveu a utiliza√ß√£o de v√°rias ferramentas:

- [Docker](https://www.docker.com/get-started/) - Plataforma para desenvolvimento, deploy e execu√ß√£o de aplica√ß√µes utilizando containers.
- [Kubernetes](https://kubernetes.io/) - Sistema de orquestra√ß√£o de containers.
- [Kind](https://kind.sigs.k8s.io/) - Ferramenta para cria√ß√£o de clusters Kubernetes locais.
- [Kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) - Ferramenta de linha de comando para interagir com o cluster Kubernetes.
- [Heml](https://helm.sh/docs/intro/install/) - Gerenciador de pacotes para Kubernetes.
- [Make](https://www.gnu.org/software/make/) - Ferramenta para automatizar a execu√ß√£o de tarefas.
- [k6](https://k6.io/) - Ferramenta para testes de carga.

### ‚öñÔ∏è Migra√ß√£o da aplica√ß√£o para o Kubernetes

 A migra√ß√£o completa da arquitetura do projeto, originalmente implementada no Docker, para o Kubernetes foi necess√°ria. O Kubernetes oferece recursos avan√ßados como Autoscaling e Load Balancer. Essas funcionalidades foram fundamentais para a decis√£o de migra√ß√£o.

#### üì¶ Arquitetura Completa

A arquitetura completa oferece uma vis√£o detalhada de todos os componentes e como eles interagem entre si.

![Arquitetura completa no Kubernetes](./.github/assets/images/k8s_complete_architecture.png)

#### üì¶ Arquitetura Simplificada

A arquitetura simplificada fornece uma vis√£o geral do sistema, focando nos componentes principais.

![Arquitetura simplificada no Kubernetes](./.github/assets/images/k8s_simplified_architecture.png)

### üí° Observa√ß√µes

#### üìå Configura√ß√£o do HPA (Horizontal Pod Autoscaling) no Kubernetes
- **Limite de CPU:** 70%
- **N√∫mero de r√©plicas m√≠nimas:** 1
- **N√∫mero de r√©plicas m√°xima:** 10

#### üìå Configura√ß√£o do teste de carga com o K6
Realizamos tr√™s testes em paralelo durante um per√≠odo de 15 minutos. Cada teste focou em um microsservi√ßo espec√≠fico e usou uma quantidade diferente de usu√°rios virtuais (VUs).

- Microsservi√ßo de Usu√°rios
    - **Endpoin:** _GET_ /users
    - **Carga:** Constante
    - **Usu√°rios Virtuais (VUs)**: 15

- Microsservi√ßo de Ordens de Compras
    - **Endpoint:** _GET_ /orders
    - **Carga:** Constante
    - **Usu√°rios Virtuais (VUs):** 10

- Microsservi√ßo de Produtos
    - **Endpoint:** _GET_ /products
    - **Carga:** Vari√°vel, dividida em 3 est√°gios:
        - **Est√°gio 1:** 30 VUs por 5 minuto
        - **Est√°gio 2:** 60 VUs por 5 minutos
        - **Est√°gio 3:** 90 VUs por 5 minutos

### üöÄ Deploy da aplica√ß√£o no Kubernetes

Para realizar o deploy da aplica√ß√£o no Kubernetes, siga os passos abaixo:

1. Criar o cluster Kubernetes local:
    ```bash
    kind create cluster
    ```
2. Configurar o monitoramento da aplica√ß√£o instalando o [kube-prometheus-stack](https://artifacthub.io/packages/helm/prometheus-community/kube-prometheus-stack):
    ```bash
    make add-prometheus-stack
    ```
3. Construir as imagens Docker dos microsservi√ßos:
    ```bash
    make docker-build-all
    ```
4. Fazer o load das imagens Docker no cluster Kubernetes (Processo demorado):
    ```bash
    make kind-load-docker-images
    ```
5. Realizar o deploy da aplica√ß√£o:
    ```bash
    make kube-up
    ```
6. Verificar se a aplica√ß√£o e o monitoramento est√£o funcionando corretamente. Todos os servi√ßos devem estar com o status `Running`:

   6.1 Verificando aplica√ß√£o
    ```bash
    kubectl get pods
    ```

    6.2 Verificando o monitoramento
    ```bash
    kubectl get pods -n monitoring
    ```

### ‚úÖ Prepara√ß√£o do teste de carga

1. Levantar o ambiente para a execu√ß√£o:
    ```bash
    make k6-up
    ```

### ‚ö†Ô∏è Realizar o experimento
1. Expor o api-gateway para acesso externo:
    ```bash
    make kube-expose-app
    ```

2. Expor o Grafana do Kubernetes para acesso externo:
    ```bash
    make kube-expose-grafana
    ```

3. Importar o dashboard do Kubernetes no grafana:

    3.1 Acessar o [grafana do Kubernetes](http://localhost:3000)

    3.2 Importar o dashboard [Kubernetes Horizontal Pod Autoscaler](./grafana/dashboards/Kubernetes_Horizontal_Pod_Autoscaler.json)

4. Importar o dashboard do K6 no grafana:

    4.1 Acessar o [grafana do K6](http://localhost:3001)

    4.1 Configurar a conex√£o com o InfluxDB:
   * URL: `http://influxdb:8086`
   * Database: `k6`

    4.2 Importar o dashboard [k6 Load Testing Results](./grafana/dashboards/k6_Load_Testing_Results.json)
        
6. Iniciar o teste de carga:
    ```bash
    make k6-run
    ```
7. Acompanhar o dashboard do K6 e do Kubernetes para verificar o comportamento da aplica√ß√£o e os resultados do teste.

8. Ao finalizar o teste de carga devemos:

    7.1 Derrubar o ambiente de execu√ß√£o do K6:
    ```bash
    make k6-down
    ```

    7.2 Derrubar o ambiente de execu√ß√£o da aplica√ß√£o:
    ```bash
    make kube-down
    ```

## ü™Ñ Resultados no Grafana

### ‚ùå Sem Autoscaling

>Microsservi√ßo de Usu√°rios

![Teste de carga usu√°rios](./.github/assets/images/test_result/no_autoscaling/USERS.png)

> Microsservi√ßo de Ordens de Compras

![Teste de carga ordens de compras](./.github/assets/images/test_result/no_autoscaling/ORDERNS.png)

>Microsservi√ßo de Produtos

![Teste de carga produtos](./.github/assets/images/test_result/no_autoscaling/PRODUCTS.png)

>Resultados K6

![Resultados K6](./.github/assets/images/test_result/no_autoscaling/K6.png)

### ‚úÖ Com Autoscaling

>Microsservi√ßo de Usu√°rios

![Teste de carga usu√°rios](./.github/assets/images/test_result/with_autoscaling/USERS.png)

> Microsservi√ßo de Ordens de Compras

![Teste de carga ordens de compras](./.github/assets/images/test_result/with_autoscaling/ORDERNS.png)

>Microsservi√ßo de Produtos

![Teste de carga produtos](./.github/assets/images/test_result/with_autoscaling/PRODUCTS.png)

>Resultados K6

![Resultados K6](./.github/assets/images/test_result/with_autoscaling/K6.png)

## üîç An√°lise

### ‚ùå Sem Autoscaling
- A utiliza√ß√£o de CPU para os microsservi√ßos de usu√°rios e ordens de compras se manteve relativamente constante entre 40%-60% e 20%-40%, respectivamente.
- Para o microsservi√ßo de produtos, a utiliza√ß√£o de CPU cresceu at√© 200% com a carga crescente.
- No K6, a maioria das requisi√ß√µes foi bem-sucedida com uma taxa de falha de 0,00%. A m√©dia da dura√ß√£o da requisi√ß√£o foi de 222,18 ms.

### ‚úÖ Com Autoscaling
- A utiliza√ß√£o de CPU para os microsservi√ßos de usu√°rios e ordens de compras se manteve relativamente constante entre 40%-50% e 20%-40%, respectivamente.
- Para o microsservi√ßo de produtos, a utiliza√ß√£o de CPU cresceu at√© 92% com a carga crescente, depois se manteve constante entre 50% e 70%.
- Durante o teste, apenas 5 de 10 r√©plicas m√°ximas foram provisionadas, permitindo um uso de CPU vari√°vel entre 50% e 70%.
- No K6, todas as requisi√ß√µes foram bem-sucedidas com uma taxa de falha de 0,90%. A m√©dia da dura√ß√£o da requisi√ß√£o foi de 125,60 ms.

## ‚ùáÔ∏è Conclus√£o
Os resultados indicam que o autoscaling foi eficaz em manter a utiliza√ß√£o da CPU na m√©dia desejada e resolver o problema de sobrecarga do sistema. Isso √© evidenciado pela redu√ß√£o na utiliza√ß√£o m√°xima da CPU no microsservi√ßo de produtos de 200% para 92%. Al√©m disso, a dura√ß√£o m√©dia da requisi√ß√£o diminuiu de 222,18 ms para 125,60 ms com o autoscaling, indicando uma melhoria no desempenho. No entanto, houve um ligeiro aumento na taxa de falha das requisi√ß√µes de 0,00% para 0,90% com o autoscaling. Isso pode ser um ponto a ser investigado para futuras otimiza√ß√µes. Em geral, o autoscaling parece ter contribu√≠do positivamente para a gest√£o da carga e o desempenho do sistema.




